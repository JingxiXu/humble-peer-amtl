{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-28 01:52:06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "print(time.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/songs.csv\n",
      "data/test.csv\n",
      "data/members.csv\n",
      "data/train.csv\n",
      "data/song_extra_info.csv\n"
     ]
    }
   ],
   "source": [
    "input_dir = 'data/'\n",
    "\n",
    "for x in glob.glob(input_dir + \"*\"):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(input_dir + \"train.csv\")\n",
    "df_test  = pd.read_csv(input_dir + 'test.csv')\n",
    "df_songs = pd.read_csv(input_dir + 'songs.csv')\n",
    "df_song_extra = pd.read_csv(input_dir + \"song_extra_info.csv\")\n",
    "df_members = pd.read_csv(input_dir + \"members.csv\", parse_dates=[\"registration_init_time\",\"expiration_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert isrc information to year\n",
    "def isrc_to_year(isrc):\n",
    "    if type(isrc) == str:\n",
    "        if int(isrc[5:7]) > 17:\n",
    "            return 1900 + int(isrc[5:7])\n",
    "        else:\n",
    "            return 2000 + int(isrc[5:7])\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df_song_extra['song_year'] = df_song_extra['isrc'].apply(isrc_to_year)\n",
    "df_song_extra.drop(['isrc', 'name'], axis = 1, inplace = True)\n",
    "# 1000 <=> 1s\n",
    "df_songs['song_length'] /= 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join train and song based on song_id\n",
    "# left join train and song_extra based on song_id\n",
    "\n",
    "df_train = df_train.merge(df_songs, how=\"left\", on=\"song_id\")\n",
    "df_train = df_train.merge(df_song_extra, how='left', on='song_id')\n",
    "df_original = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "catagorical columns: ['msno', 'song_id', 'source_system_tab', 'source_screen_name', 'source_type', 'genre_ids', 'artist_name', 'composer', 'lyricist']\n",
      "numerical columns: ['target', 'song_length', 'language', 'song_year']\n"
     ]
    }
   ],
   "source": [
    "# # change object columns to str type\n",
    "# catagorical_cols = []\n",
    "# numerical_cols = []\n",
    "\n",
    "# for col in df_train.columns:\n",
    "#     if df_train[col].dtype == 'object':\n",
    "#         catagorical_cols.append(col)\n",
    "#         df_train[col] = df_train[col].astype('str')\n",
    "#     else:\n",
    "#         numerical_cols.append(col)\n",
    "# print('catagorical columns: {}'.format(catagorical_cols))\n",
    "# print('numerical columns: {}'.format(numerical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7377418,)\n",
      "(30755,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['msno', 'song_id', 'source_system_tab', 'source_screen_name',\n",
       "       'source_type', 'target', 'song_length', 'genre_ids', 'artist_name',\n",
       "       'composer', 'lyricist', 'language', 'song_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 359966 unique users\n",
    "# 7377418 song user pairs\n",
    "print(df_train['msno'].shape)\n",
    "print(df_train['msno'].unique().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with NaN\n",
    "- catagorical -> fill in \"Unknown\" \n",
    "- numerical -> fill in mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object     source_system_tab\n",
      "object     source_screen_name\n",
      "object     source_type\n",
      "float64    song_length\n",
      "object     genre_ids\n",
      "object     artist_name\n",
      "object     composer\n",
      "object     lyricist\n",
      "float64    language\n",
      "float64    song_year\n"
     ]
    }
   ],
   "source": [
    "for col in df_train.columns:\n",
    "    if df_train[col].isnull().any():\n",
    "        print('{:10} {}'.format(str(df_train[col].dtype), col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill categorical columns with tag: 'Unknown'\n",
    "UNKNOWN = 'Unknown'\n",
    "col_catagorical = ['source_system_tab', 'source_screen_name', 'source_type', 'genre_ids', 'artist_name', 'composer', 'lyricist']\n",
    "for col in col_catagorical:\n",
    "    df_train[col].fillna(value=UNKNOWN, inplace=True)\n",
    "    \n",
    "fill_in_value = df_train['song_length'].mean()\n",
    "df_train['song_length'].fillna(value=fill_in_value,inplace=True)\n",
    "\n",
    "fill_in_value = df_train['song_year'].median()\n",
    "df_train['song_year'].fillna(value=fill_in_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- binary features\n",
    "- count features\n",
    "- historical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean song lengths greater than 1800\n",
    "df_train.loc[df_train['song_length'] > 1800, 'song_length'] = 1800\n",
    "\n",
    "# count the number of genres\n",
    "def _count(x):\n",
    "    if x == UNKNOWN:\n",
    "        return 0\n",
    "    else:\n",
    "        return sum(map(x.count, ['|', '/', '\\\\', ';', '„ÄÅ', ','])) + 1\n",
    "\n",
    "# new feature: the number of genres for each song\n",
    "df_train['genre_count'] = df_train['genre_ids'].apply(_count).astype(int)\n",
    "\n",
    "# new feature: the number of lyricists for each song\n",
    "df_train['lyricist_count'] = df_train['lyricist'].apply(_count).astype(int)\n",
    "\n",
    "# new feature: the number of composers for each song\n",
    "df_train['composer_count'] = df_train['composer'].apply(_count).astype(int)\n",
    "\n",
    "# the number of artists\n",
    "def artist_count(x):\n",
    "    if x == UNKNOWN:\n",
    "        return 0\n",
    "    else:\n",
    "        return x.count('and') + x.count(',') + x.count('feat') + x.count('&') + 1\n",
    "    \n",
    "# new feature: the number of artists for each song\n",
    "df_train['artist_count'] = df_train['artist_name'].apply(artist_count).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the artist name includes 'is_featured'\n",
    "def is_featured(x):\n",
    "    if 'feat' in str(x) :\n",
    "        return 1\n",
    "    return 0\n",
    "df_train['is_featured'] = df_train['artist_name'].apply(is_featured).astype(np.int8)\n",
    "\n",
    "# if artist is same as composer\n",
    "df_train['artist_composer'] = (df_train['artist_name'] == df_train['composer']).astype(np.int8)\n",
    "\n",
    "# if artist, lyricist and composer are all three same\n",
    "df_train['artist_composer_lyricist'] = ((df_train['artist_name'] == df_train['composer']) \n",
    "                                        & (df_train['artist_name'] == df_train['lyricist']) \n",
    "                                        & (df_train['composer'] == df_train['lyricist'])).astype(np.int8)\n",
    "\n",
    "# if song language is 17 or 45. \n",
    "def song_lang_boolean(x):\n",
    "    if '17.0' in str(x) or '45.0' in str(x):\n",
    "        return 1\n",
    "    return 0\n",
    "df_train['song_lang_boolean'] = df_train['language'].apply(song_lang_boolean).astype(np.int8)\n",
    "\n",
    "# if the song's length is shorter than mean\n",
    "_mean_song_length = np.mean(df_train['song_length'])\n",
    "def smaller_song(x):\n",
    "    if x < _mean_song_length:\n",
    "        return 1\n",
    "    return 0\n",
    "df_train['smaller_song'] = df_train['song_length'].apply(smaller_song).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of times a song has been played before\n",
    "_dict_count_song_played_train = {k: v for k, v in df_train['song_id'].value_counts().iteritems()}\n",
    "def count_song_played(x):\n",
    "    try:\n",
    "        return _dict_count_song_played_train[x]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "df_train['count_song_played'] = df_train['song_id'].apply(count_song_played).astype(np.int64)\n",
    "del _dict_count_song_played_train\n",
    "\n",
    "# number of times the artist has been played\n",
    "_dict_count_artist_played_train = {k: v for k, v in df_train['artist_name'].value_counts().iteritems()}\n",
    "def count_artist_played(x):\n",
    "    try:\n",
    "        return _dict_count_artist_played_train[x]\n",
    "    except KeyError:\n",
    "        return 0\n",
    "df_train['count_artist_played'] = df_train['artist_name'].apply(count_artist_played).astype(np.int64)\n",
    "del _dict_count_artist_played_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many tasks we have\n",
    "temp = df_train.groupby('msno').count()\n",
    "temp.loc[temp['song_id']>100].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct numpy data matrices\n",
    "catagorical columns\n",
    "- source_system_tab\n",
    "- source_screen_name\n",
    "- source_type\n",
    "- genre_ids\n",
    "- artist_name\n",
    "- composer\n",
    "- lyricist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['source_system_tab', 'source_screen_name', 'source_type', 'genre_ids', 'artist_name', 'composer', 'lyricist']\n"
     ]
    }
   ],
   "source": [
    "# find all catagorical columns\n",
    "catagorical_cols = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'object' and col != 'msno' and col != 'song_id':\n",
    "        catagorical_cols.append(col)\n",
    "print(catagorical_cols)\n",
    "\n",
    "# convert all object types to str\n",
    "for col in catagorical_cols:\n",
    "    df_train[col] = df_train[col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['song_length', 'language', 'song_year', 'genre_count', 'lyricist_count', 'composer_count', 'artist_count', 'is_featured', 'artist_composer', 'artist_composer_lyricist', 'song_lang_boolean', 'smaller_song', 'count_song_played', 'count_artist_played']\n"
     ]
    }
   ],
   "source": [
    "# find all numerical columns\n",
    "numerical_cols = [x for x in df_train.columns if x not in ['msno', 'song_id', 'target'] and x not in catagorical_cols]\n",
    "print(numerical_cols)\n",
    "\n",
    "# convert all numerical types to float\n",
    "for col in numerical_cols:\n",
    "    df_train[col] = df_train[col].astype('float')\n",
    "    \n",
    "df_train['target'] = df_train['target'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frop song_id column which is not useful\n",
    "df_train.drop(['song_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_system_tab     9\n",
      "source_screen_name    20\n",
      "source_type           13\n",
      "genre_ids             573\n",
      "artist_name           40583\n",
      "composer              76064\n",
      "lyricist              33888\n",
      "overall dimension:   151164\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "\n",
    "# print number of unique numbers\n",
    "for col in catagorical_cols:\n",
    "    sum += df_train[col].unique().shape[0]\n",
    "    print('{:20}  {}'.format(col, df_train[col].unique().shape[0]))\n",
    "\n",
    "# overall dimension of a single data point\n",
    "# categorical dimension + numerical dimension\n",
    "dimension = sum + 14\n",
    "print('{:20} {}'.format('overall dimension:', dimension))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit encoders for all catagorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "label_encoder = {}\n",
    "onehot_encoder = {}\n",
    "for col in catagorical_cols:\n",
    "    label_encoder[col] = LabelEncoder()\n",
    "    label_encoder[col].fit(df_train[col].unique())\n",
    "    label_encoded = label_encoder[col].transform(df_train[col].unique())\n",
    "    onehot_encoder[col] = OneHotEncoder(sparse=False)\n",
    "    onehot_encoder[col].fit(label_encoded.reshape(-1, 1))\n",
    "\n",
    "def get_onehot_encoded(group, col):\n",
    "    label_encoded = label_encoder[col].transform(group[col]).reshape(-1, 1)\n",
    "    onehot_encoded = onehot_encoder[col].transform(label_encoded)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "umber of total users 30755\n",
      "number of users with more than 1000 data:  932\n"
     ]
    }
   ],
   "source": [
    "grouped = df_train.groupby('msno')\n",
    "grouped_count = grouped.count()\n",
    "\n",
    "num_users = df_train['msno'].unique().shape[0]\n",
    "print('\\number of total users {}'.format(num_users))\n",
    "num_users_rich = grouped_count.loc[grouped_count['source_system_tab']>=1000].shape[0]\n",
    "print('number of users with more than 1000 data: ', num_users_rich)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find user groups with enough data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user ID: +22Q6EpFwjgJhiiGWz7GQUiq5yu0adEEZWH8j/fj19w=, data shape: (1006, 151164)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from scipy import sparse\n",
    "\n",
    "data = []\n",
    "gt = []\n",
    "# each data point is under the following format\n",
    "# [0:9] source_system_tab\n",
    "# [9:29] source_screen_name\n",
    "# [29:42] source_type\n",
    "# [42:615] genre_ids\n",
    "# [615:41198] artist_name\n",
    "# [41198:117262] composer\n",
    "# [117262:151150] lyricist\n",
    "# [151150: 151164] 14 numerical columns\n",
    "count = 0\n",
    "for name, group in grouped:\n",
    "    if group.shape[0] >= 1000:\n",
    "        # user data matrix\n",
    "        user_data = np.zeros((group.shape[0], 1))\n",
    "        for col in catagorical_cols:\n",
    "            user_data = np.concatenate([user_data, get_onehot_encoded(group, col)], axis=1)\n",
    "        for col in numerical_cols:\n",
    "            user_data = np.concatenate([user_data, group[col].values.reshape(-1, 1)], axis=1)\n",
    "        user_data = np.delete(user_data, 0, axis=1)\n",
    "        # user groud truth matrix\n",
    "        user_gt = group['target']\n",
    "        \n",
    "        # convert to sparse matrices\n",
    "        user_data = sparse.csr_matrix(user_data)\n",
    "        user_gt = sparse.csr_matrix(user_gt)\n",
    "        \n",
    "        data.append(user_data)\n",
    "        gt.append(user_gt)\n",
    "        count += 1\n",
    "        print(\"user ID: {}, data shape: {}\".format(name, user_data.shape))\n",
    "        if count == 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save to pickle data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.data', 'bw') as f:\n",
    "    pickle.dump(data, f)\n",
    "with open('./gt.data', 'bw') as f:\n",
    "    pickle.dump(gt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1006, 151164)\n",
      "(1, 1006)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1006x151164 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 15925 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(user_data.shape)\n",
    "print(user_gt.shape)\n",
    "user_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bastille' 'Various Artists' 'Nas' ... 'JD Samson & MEN'\n",
      " '2002 Latin Love Songs' 'Salvina y Miren al Lobo']\n"
     ]
    }
   ],
   "source": [
    "artists = df_train['artist_name'].unique()\n",
    "print(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3277 31961 21372 ... 13653   187 25747]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "['Bastille']\n"
     ]
    }
   ],
   "source": [
    "# integer encoder\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(artists)\n",
    "print(integer_encoded)\n",
    "\n",
    "# one-hot encoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(onehot_encoded)\n",
    "\n",
    "# # invert first example\n",
    "# inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
    "# print(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55962745, 0.68493498, 0.5639901 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.73142811, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.98572975, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "A = lil_matrix((1000, 1000))\n",
    "A[0, :100] = np.random.rand(100)\n",
    "A[1, 100:200] = A[0, :100]\n",
    "A.setdiag(np.random.rand(1000))\n",
    "\n",
    "\n",
    "B = np.zeros((10000, 1000))\n",
    "B[:1000, :1000] = A.toarray()\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25990086, 0.59799831, 0.2493278 ],\n",
       "       [0.95983736, 0.47735211, 0.21574678]])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(2, 3)\n",
    "n = np.random.rand(2, 10)\n",
    "np.concatenate([a, n], axis=1).shape\n",
    "np.concatenate([a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25990086, 0.2493278 ],\n",
       "       [0.95983736, 0.21574678]])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(a, 1, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
